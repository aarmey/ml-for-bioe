---
title: Course outline
layout: page
---

### Week 1, Jan 3 – 7

- [Lecture 1: Statistics review](../public/Wk1-Lecture1.pdf) (Recording part [1](https://www.youtube.com/watch?v=9fXyIDgLiRU), [2](https://www.youtube.com/watch?v=jcLIxxLo5_A))
  - Reading: [Can a biologist fix a radio?](https://www.cell.com/cancer-cell/fulltext/S1535-6108(02)00133-2)
  - Listening: [Linear Digressions: The Normal Distribution and the Central Limit Theorem](http://lineardigressions.com/episodes/2018/12/9/the-normal-distribution-and-the-central-limit-theorem)
- [Lecture 2: Fitting & Regression](../public/Wk1-Lecture2.pdf) (Recording part [1](https://www.youtube.com/watch?v=-lG53OEl1-s), [2](https://www.youtube.com/watch?v=k0xUp8DPNIA))
  - [Example Notebook](../public/examples/OLS-Example.ipynb)
  - Listening: [Linear Digressions: The assumptions of ordinary least squares](http://lineardigressions.com/episodes/2019/1/12/the-assumptions-of-ordinary-least-squares)
  - Reading: [Points of Significance: Simple linear regression](http://www.nature.com/nmeth/journal/v12/n11/full/nmeth.3627.html)
  - Listening: [Linear Digressions: Convex (and non-convex) optimization](http://lineardigressions.com/episodes/2018/12/16/convex-and-non-convex-optimization)
- Lab: Programming and Git Primer, due 1/13 at 11:59 pm
  - Listening: [Linear Digressions: Jupyter Notebooks, A Data Scientist's Best Friend](https://lineardigressions.com/episodes/2017/8/20/jupyter-notebooks-a-data-scientists-best-friend)
  - Listening: [Linear Digressions: Git for Data Scientists](https://lineardigressions.com/episodes/2018/6/3/git-for-data-scientists)

### Week 2, Jan 10 – 14

- [Lecture 3: Fitting & Regression Redux, Regularization](../public/Wk2-Lecture3.pdf) (Recording part [1](https://www.youtube.com/watch?v=J3rF6vP3tQY), [2](https://youtu.be/-jRZ7POBsrQ), [3](https://youtu.be/TRLPmD4uQYE))
  - [Example Notebook](../public/examples/Regularization-Example.ipynb)
- [Lecture 4: Does my model work? Crossvalidation, bootstrap, and friends](../public/Wk2-Lecture4.pdf) (Recording part [1](https://youtu.be/N4afdo1VQB0), [2](https://youtu.be/OdEGD35sO-8))
  - [Example Notebook](../public/examples/CrossVal-Example.ipynb)
- Reading: [Points of Significance: Regression Diagnostics](https://www.nature.com/nmeth/journal/v13/n5/abs/nmeth.3854.html)
- Lab: Implementation of [Shaffer et al.](https://www.nature.com/nature/journal/v546/n7658/abs/nature22794.html), due 1/20 at 11:59 pm ([starter link](https://classroom.github.com/a/AEQurBHX))

### Week 3, Jan 17 – 21

- [Lecture 5: Bayesian vs. frequentist approaches](../public/Wk3-Lecture5.pdf) (Recording part [1](https://youtu.be/8lOjdH_ZfVc), [2](https://youtu.be/Cu3kkOu9juY))
  - [Linear Digressions: Beware of simple metrics](http://lineardigressions.com/episodes/2019/12/22/data-scientists-beware-of-simple-metrics)
- [Lecture 6: Reproducible computational workflows](../public/Wk3-Lecture6.pdf) ([Recording](https://youtu.be/Rh2SdM2_IIg))
- Lab: Implementation of [Stone et al.](http://www.sciencedirect.com/science/article/pii/S0006349501758997), due 1/27 at 11:59 pm ([starter link](https://classroom.github.com/a/1tG08HU3))

### Week 4, Jan 24 – 28

- [Lecture 7: Dimensionality reduction - PCA and NMF](../public/Wk4-Lecture7.pdf) (Recording part [1](https://youtu.be/mPuV7y5ZRfo), [2](https://youtu.be/1_43nCptm44))
  - [Example Notebook](../public/examples/PCA-NNMF.ipynb)
  - If you would like a visual refresh of linear algebra [look here](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
  - Reading: [Points of Significance: Principal Components Analysis](https://www.nature.com/articles/nmeth.4346)
- [Lecture 8: Partial Least Squares Regression](../public/Wk4-Lecture8.pdf) (Recording part [1](https://youtu.be/C8lb1vnr8OQ), [2](https://youtu.be/kfDwh_elvC8), [3](https://youtu.be/W49gD36Iga4))
- Lab: Implementation of [Cosgrove et al.](http://pubs.rsc.org/en/Content/ArticleLanding/2010/MB/b926287c), due 2/3 at 11:59 pm ([starter link](https://classroom.github.com/a/7x_NtH4i))

### Week 5, Jan 31 – Feb 4

- [Lecture 9: Dynamical models](../public/Wk5-Lecture09.pdf)
- Lecture 10: Finish dynamical models
  - Guest presentation: Dynamical models of the cell cycle
- Lab: Midterm review, finish selecting project

### Week 6, Feb 7 – 11

- [Final project proposals due 2/11 at 8 pm](https://bruinlearn.ucla.edu/courses/111529/assignments/947467)
- [Create project repository](https://classroom.github.com/a/An4Bf0du)
- Lecture 11: Midterm review (previous midterms: [W18](../files/midterm-W18.pdf), [W19](../files/midterm-W19.pdf), [W20](../files/midterm-W20.pdf), [F21](../files/midterm-F21.pdf))
- Lecture 12: Midterm exam
- Lab: Implementation of [Perelson et al.](http://science.sciencemag.org/content/271/5255/1582), due 2/17 at 11:59 pm ([starter link](https://classroom.github.com/a/weG03uDz))


### Week 7, Feb 14 – 18

- [Lecture: Hidden Markov Models](../public/Wk5-Lecture10.pdf)
  - [Example Notebook](../public/examples/HMMs-example.ipynb)
  - Reading: [What is a hidden Markov model?](https://www.nature.com/articles/nbt1004-1315)
  - Reading: [Markov Models—Markov chains](https://www.nature.com/articles/s41592-019-0476-x)
  - Reading: [Markov Models—Hidden Markov models](https://www.nature.com/articles/s41592-019-0532-6)
  - Reading: [Markov models—Training and evaluation of hidden Markov models](https://www.nature.com/articles/s41592-019-0702-6)
  - Listening: [Linear Digressions - Hidden Markov Models](http://lineardigressions.com/episodes/2016/2/23/introducing-hidden-markov-models-hmm-part-1) ([part 2](http://lineardigressions.com/episodes/2016/2/23/genetics-and-um-detection-hmms-part-2))
- Lecture: Finish hidden Markov models.
- Lab: Implementation of HMMs for heart rate monitor wearable, due 2/24 at 11:59 pm ([starter link](https://classroom.github.com/a/kK-E9fUb))

### Week 8, Feb 21 – 25

- [Lecture 13: K-Means Clustering](../public/Wk7-Lecture13.pdf)
  - [Example Notebook](../public/examples/K-Means.ipynb)
- [Lecture 14: Gaussian Mixture Models](../public/Wk7-Lecture14.pdf)
  - [Example Notebook](../public/examples/Gaussian-Mixtures.ipynb)
  - Guest presentation: Using sequence information to improve clustering

### Week 9, Feb 28 – Mar 4

- [Lecture 16: Support vector machines](../public/Wk8-Lecture16.pdf)
  - [Example Notebook](../public/examples/SVMs-example.ipynb)
  - Listening: [Linear Digressions: Maximal Margin Classifiers](http://lineardigressions.com/episodes/2017/12/3/maximal-margin-classifiers)
  - Listening: [Linear Digressions: The Kernel Trick and Support Vector Machines](http://lineardigressions.com/episodes/2017/12/10/the-kernel-trick-and-support-vector-machines)
- Lab: Implementation of [Masaeli et al.](https://www.nature.com/articles/srep37863), due 3/15 at 11:59 pm ([starter link](https://classroom.github.com/a/-i7dn1tU))

### Week 10, Mar 7 – 11

- Lecture: Project presentations
- Lab: Further project implementation
- Final Project, due 3/17 at noon (submit through project Github repository)
